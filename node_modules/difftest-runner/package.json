{
  "name": "difftest-runner",
  "version": "0.0.2",
  "description": "A simple utility to assist in the exeuction of diff based tests. ",
  "directories": {
    "bin": "./bin"
  },
  "repository": {
    "type": "git",
    "url": "http://github.com/intimonkey/difftest-runner.git"
  },
  "keywords": [
    "diff",
    "test",
    "runner"
  ],
  "author": {
    "name": "Ian Groff"
  },
  "readmeFilename": "README.md",
  "license": "BSD",
  "bugs": {
    "url": "https://github.com/intimonkey/difftest-runner/issues"
  },
  "dependencies": {},
  "bin": {
    "difftest": "bin/difftest",
    "difftest_create": "bin/difftest_create",
    "difftest_default": "bin/difftest_default",
    "difftest_edit": "bin/difftest_edit",
    "difftest_init": "bin/difftest_init",
    "difftest_pass": "bin/difftest_pass",
    "difftest_run": "bin/difftest_run",
    "difftest_show": "bin/difftest_show",
    "difftest_show_tests": "bin/difftest_show_tests",
    "utils": "bin/utils"
  },
  "readme": "# difftest-runner\ndifftest-runner helps run and track the output of test scripts so you can quickly\ndetermine if things are the same as they were when you decided they were 'good'.\n\n## NOTE!\nI'm not a node app, I use npm for distribution because it's simple and\nstraight-forward.  I'm a collection of bash scripts, thus should run most\nanywhere bash does, but that's not been verified in any way. That's not to\nsay there's no intention I run elsewhere, just that nothing's been done to\nmake it so.\n\n\n### So.... What Now?\nYou'd be hard pressed to find something in Software Engineering that doesn't need or couldn't benefit from some automated testing.  It sucks to make a trivial change to something and not be able to have an equally trivial answer to the question \"Well, I wonder if that change broke anything?\".  So with that, testing is a must.  \n\n  Testing, however can be done in a bunch of different ways. The simplest \napproach to writing a test is pretty straight forward:\n\n* do something\n* see what happens\n* decide if that's good, or make changes until it is so\n* record that output for later comparison\n\nUsing a test is even easier:\n\n* remember that thing you did? do it again\n* compare the output to what you decided was good (above)\n\nThis is the gist of damn near every testing framework in the world, and they\nall have various approaches to all aspects of that process, and generally try\nand be available in every single environment you can imagine. Here we try to\nignore how, what, and environment and focus only on facilitating the\n'given something done' what does it's output look like and, does that output\nlook like what it used to.\n\n#### All that is the long winded version of this\ndifftest-runner is a series of scripts that aim to make the execution of and collection of the output from a body of tests (scripts) easily repeatable\nsuch that you can compare future executions to executions deemed 'good'.\n\n\n### Things to Know\n\ndifftest-runner is distribted using npm.  This isn't because it's javascript,\nor uses node because it's not and doesn't, but because npm is easy to use and\ngood at this 'package and distribute' thing.\n\nThere is a specific directory structure that difftest-runner uses, mostly you\ndon't have to care and can just interact with this through the commands provided\nbut it's good to know what the hell all this is:\n\n    difftest \n      |-tests\n      |-expected\n      |-results\n      |-filters\n\nIn the example, the root directory is called 'difftest' which is the default.\nWhile it's technically possible to change this, why would we want to have that\ncomplexity? \n\n* `/difftest/tests` - This directory contains the 'scripts' that are run to do\nthe 'testing'.  Generally I think of these items as scripts but they simply\nneed to be exec-able, and return some deterministic output to stdout.\n\n* `/difftest/expected` - This is where the 'good' output of the scripts is stored\nfor future comparison.  Each test in the `tests/` directory should have a corresponding\nfile here which contains the output from the test that is considered good.\n\n* `/difftest/results` - This is where the output of the last run of each test is\nstored.  Each test in the `tests/` directory will create a file in this directory\ncontaining the captured output from stdout and stderr from the most recent run\nof the tests.\n\n* `/difftest/filters` - This contains filters to be applied to test output to\nmake things that vary (like time stamps) fixed so comparison of output\nis simplified.  Oh, and... If you put a filter in here named 'default' and ther is\nno test specific filter, that one (the default) will be used.\n\ndifftest-runner doesn't care what your tests do, a big part of this was to create\nsomething that worked the same regardless of implementation of the 'system under\ntest'. The whole point is only that test produce output on stdout and stderr,\ndifftest compares that to previous output.\n\n### So how do I use it?\n\n1. Install it \n\n        npm install -g difftest-runner\n\n1. Initialize the directory you want to have tests in, I find this to be the root \nof my repository.\n\n        difftest init\n\n1. Make a test, currently the template test is nothing more than a stub of a \nbash script.   \n\n        difftest create my_first_test\n\n1. See that the test is really there\n    \n        difftest show tests\n\n1. Edit the test to make it do something, this relies on the environment variable\n```EDITOR``` being set.\n  \n        difftest edit my_first_test\n\n1. See that it fails (we haven't defined passing yet!)\n  \n        difftest run\n\n1. Check the results of the last test run for my\\_first\\_test\n\n        difftest show my_first_test\n\n1. Tell difftest that the results of the test are good\n\n        difftest pass my_first_test\n\n1. See what victory looks like!\n  \n        difftest run\n\n### Examples\nHere are some examples of actual tests from somewhere else:\n\ndifftest/tests/non_existant_doc \n\n    #! /usr/bin/env bash\n    # vi:ft=sh\n    curl -s -w \"\\n%{http_code}\" http://localhost:8080/this/key/shouldnt/exist\n\ndifftest/expected/non_existant_doc\n\n    {\n      \"message\": \"no document matching key\"\n    }\n    200\n\ndifftest/tests/delete_doc\n\n    #! /usr/bin/env bash\n    # vi:ft=sh\n    KEY_PATH=`uuidgen`\n    curl -s http://localhost:8080/this/is/a/test/key/${KEY_PATH}\n    curl -s -X PUT http://localhost:8080/this/is/a/test/key/${KEY_PATH} --data '{\"name\":\"pants\"}' -H 'Content-Type: application/json'\n    curl -s http://localhost:8080/this/is/a/test/key/${KEY_PATH}\n    curl -s -X DELETE http://localhost:8080/this/is/a/test/key/${KEY_PATH}\n    curl -s http://localhost:8080/this/is/a/test/key/${KEY_PATH}\n\ndifftest/results/delete_doc\n\n    {\n      \"message\": \"no document matching key\"\n    }{\n      \"message\": \"it's put\"\n    }{\"name\":\"pants\"}{\n      \"message\": \"deleted\"\n    }{\n      \"message\": \"no document matching key\"\n    }\n\n### TODO\n\n* allow for the creation of custom test templates\n",
  "homepage": "https://github.com/intimonkey/difftest-runner",
  "_id": "difftest-runner@0.0.2",
  "_from": "difftest-runner@"
}
